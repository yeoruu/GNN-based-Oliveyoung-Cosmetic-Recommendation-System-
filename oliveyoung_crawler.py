import os
import re
import time
import pandas as pd
from playwright.sync_api import sync_playwright, TimeoutError as PWTimeoutError

CATEGORY = "í¬ë¦¼"
START_URL = "https://www.oliveyoung.co.kr/store/display/getMCategoryList.do?dispCatNo=100000100010014&isLoginCnt=0&aShowCnt=0&bShowCnt=0&cShowCnt=0&gateCd=Drawer&trackingCd=Cat100000100010014_MID&trackingCd=Cat100000100010014_MID&t_page=%EB%93%9C%EB%A1%9C%EC%9A%B0_%EC%B9%B4%ED%85%8C%EA%B3%A0%EB%A6%AC&t_click=%EC%B9%B4%ED%85%8C%EA%B3%A0%EB%A6%AC%ED%83%AD_%EC%A4%91%EC%B9%B4%ED%85%8C%EA%B3%A0%EB%A6%AC&t_1st_category_type=%EB%8C%80_%EC%8A%A4%ED%82%A8%EC%BC%80%EC%96%B4&t_2nd_category_type=%EC%A4%91_%EC%97%90%EC%84%BC%EC%8A%A4%2F%EC%84%B8%EB%9F%BC%2F%EC%95%B0%ED%94%8C"
OUT_CSV = "table2_cream_basic.csv"

MAX_SCROLL_PER_PAGE = 30      
SCROLL_WAIT_MS = 650
POLITE_SLEEP_SEC = 0.7        

def normalize_url(href: str) -> str:
    """URL ì •ê·œí™”"""
    if href.startswith("/"):
        return "https://www.oliveyoung.co.kr" + href
    return href

def load_existing():
    """ê¸°ì¡´ CSV íŒŒì¼ì´ ìˆìœ¼ë©´ ë¡œë“œ"""
    if os.path.exists(OUT_CSV):
        df = pd.read_csv(OUT_CSV)
        seen = set(df["product_url"].astype(str).tolist())
        return df, seen
    return pd.DataFrame(columns=["product_id", "category", "brand", "product_name", "product_url"]), set()

def click_view_48(page):
    """VIEW 48 ìˆìœ¼ë©´ í´ë¦­"""
    try:
        page.locator("text=48").first.click(timeout=1200)
        page.wait_for_timeout(800)
    except:
        pass

def scroll_for_loading_products(page, max_scroll=MAX_SCROLL_PER_PAGE, verbose=False):
    """
    âœ… ìƒí’ˆ lazy-loadë¥¼ ëê¹Œì§€ ë¶™ì´ê¸° ìœ„í•œ ìŠ¤í¬ë¡¤
    """
    if verbose:
        print(f"  ğŸ“œ ìƒí’ˆ ë¡œë”©ì„ ìœ„í•œ ìŠ¤í¬ë¡¤ ì‹œì‘ (ìµœëŒ€ {max_scroll}íšŒ)...")
    
    last_cnt = -1
    stable = 0
    for i in range(max_scroll):
        page.mouse.wheel(0, 2800)
        page.wait_for_timeout(SCROLL_WAIT_MS)

        cnt = page.locator('a[href*="getGoodsDetail.do"]').count()
        if cnt == last_cnt:
            stable += 1
        else:
            stable = 0
            last_cnt = cnt

        if stable >= 2:
            if verbose:
                print(f"  âœ… ìƒí’ˆ ë¡œë”© ì™„ë£Œ ({i+1}íšŒ ìŠ¤í¬ë¡¤, {cnt}ê°œ ìƒí’ˆ ë°œê²¬)")
            break
    
    if verbose and stable < 2:
        print(f"  âœ… ìŠ¤í¬ë¡¤ ì™„ë£Œ ({max_scroll}íšŒ, {last_cnt}ê°œ ìƒí’ˆ ë°œê²¬)")

def scroll_to_pagination_bottom(page):
    """
    âœ… í˜ì´ì§€ ì´ë™ì„ ìœ„í•´ 'ë§¨ ì•„ë˜ í˜ì´ì§€ë„¤ì´ì…˜'ì´ í™”ë©´ì— ë³´ì´ë„ë¡ ëê¹Œì§€ ë‚´ë ¤ê°
    """
    page.evaluate("window.scrollTo(0, document.body.scrollHeight);")
    page.wait_for_timeout(700)

def extract_products_on_page(page, seen_urls: set, verbose=False):
    """í˜„ì¬ í˜ì´ì§€ì—ì„œ ì œí’ˆ ì •ë³´ ì¶”ì¶œ"""
    rows = []
    cards = page.locator('a[href*="getGoodsDetail.do"]')
    n = cards.count()
    
    if verbose:
        print(f"  ğŸ” ë°œê²¬ëœ ìƒí’ˆ ì¹´ë“œ: {n}ê°œ")

    for i in range(n):
        a = cards.nth(i)
        href = a.get_attribute("href")
        if not href:
            continue

        product_url = normalize_url(href)
        if product_url in seen_urls:
            continue

        container = a.locator("xpath=ancestor::li[1]")

        brand = None
        for sel in [".tx_brand", ".prd_brand", ".brand"]:
            loc = container.locator(sel)
            if loc.count() > 0:
                t = loc.first.inner_text().strip()
                if t:
                    brand = t
                    break

        name = None
        for sel in [".tx_name", ".prd_name", ".name"]:
            loc = container.locator(sel)
            if loc.count() > 0:
                t = loc.first.inner_text().strip()
                if t and len(t) >= 2:
                    name = t
                    break

        if not name:
            try:
                name = a.inner_text().strip()
            except:
                name = None

        rows.append({
            "brand": brand,
            "product_name": name,
            "category": CATEGORY,
            "product_url": product_url
        })
        seen_urls.add(product_url)

    if verbose:
        new_count = len(rows)
        duplicate_count = n - new_count
        print(f"  ğŸ“¦ ìƒˆë¡œ ìˆ˜ì§‘ëœ ì œí’ˆ: {new_count}ê°œ (ì¤‘ë³µ ì œì™¸: {duplicate_count}ê°œ)")

    return rows

def get_current_page_num(page) -> int:
    """í˜ì´ì§€ë„¤ì´ì…˜ì—ì„œ í˜„ì¬ í˜ì´ì§€ ì°¾ê¸°"""
    for sel in ["div.pageing strong", "strong.on", "a.on", "span.on", "a.active", "span.active", "strong"]:
        loc = page.locator(sel)
        if loc.count() > 0:
            txt = loc.first.inner_text().strip()
            if txt.isdigit():
                return int(txt)

    try:
        nums = page.locator("div.pageing a").filter(has_text=re.compile(r"^\d+$"))
        if nums.count() > 0:
            return int(nums.first.inner_text().strip())
    except:
        pass
    
    try:
        nums = page.locator("a, button").filter(has_text=re.compile(r"^\d+$"))
        if nums.count() > 0:
            for i in range(nums.count()):
                elem = nums.nth(i)
                classes = elem.get_attribute("class") or ""
                if "on" in classes or "active" in classes or "current" in classes:
                    txt = elem.inner_text().strip()
                    if txt.isdigit():
                        return int(txt)
            txt = nums.first.inner_text().strip()
            if txt.isdigit():
                return int(txt)
    except:
        pass
    
    raise RuntimeError("í˜„ì¬ í˜ì´ì§€ ë²ˆí˜¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

def click_page_number(page, target: int, verbose=False) -> bool:
    """
    âœ… ë§¨ ì•„ë˜ í˜ì´ì§€ë„¤ì´ì…˜ì—ì„œ target ìˆ«ìë¥¼ í´ë¦­í•˜ì—¬ í˜ì´ì§€ ì´ë™
    âœ… 10, 20, 30... ë‹¨ìœ„ ë„˜ì–´ê°ˆ ë•Œ "ë‹¤ìŒ" ë²„íŠ¼ ìë™ í´ë¦­
    """
    if verbose:
        print(f"    ğŸ” {target}ë²ˆ í˜ì´ì§€ ë§í¬ ì°¾ëŠ” ì¤‘...")
    
    scroll_to_pagination_bottom(page)

    # ë¨¼ì € í˜„ì¬ í˜ì´ì§€ê°€ targetì¸ì§€ í™•ì¸ (strong íƒœê·¸)
    try:
        strong = page.locator("strong[title='í˜„ì¬ í˜ì´ì§€']")
        if strong.count() > 0:
            current_text = strong.first.inner_text().strip()
            if current_text == str(target):
                if verbose:
                    print(f"    âœ… ì´ë¯¸ {target}ë²ˆ í˜ì´ì§€ì— ìˆìŒ (strong íƒœê·¸)")
                return True  # ì´ë¯¸ í•´ë‹¹ í˜ì´ì§€ì— ìˆìœ¼ë¯€ë¡œ ì„±ê³µ
    except:
        pass

    loc = None
    try:
        # ë°©ë²• 1: data-page-no ì†ì„±ìœ¼ë¡œ ì°¾ê¸° (a íƒœê·¸ë§Œ í•´ë‹¹)
        temp_loc = page.locator(f"a[data-page-no='{target}']")
        if temp_loc.count() > 0:
            loc = temp_loc.first
            if verbose:
                print(f"    âœ… {target}ë²ˆ í˜ì´ì§€ ë°œê²¬ (data-page-no)")
    except:
        pass
    
    if loc is None:
        try:
            # ë°©ë²• 2: div.pageing ì•ˆì˜ a íƒœê·¸
            temp_loc = page.locator("div.pageing a").filter(has_text=re.compile(rf"^{target}$"))
            if temp_loc.count() > 0:
                txt = temp_loc.first.inner_text().strip()
                if txt == str(target):
                    loc = temp_loc.first
                    if verbose:
                        print(f"    âœ… {target}ë²ˆ í˜ì´ì§€ ë§í¬ ë°œê²¬ (div.pageing a)")
        except:
            pass
    
    if loc is None:
        try:
            # ë°©ë²• 3: ì „ì²´ a ì¤‘ ìˆ«ì ì°¾ê¸°
            temp_loc = page.locator("a").filter(has_text=re.compile(rf"^{target}$"))
            if temp_loc.count() > 0:
                txt = temp_loc.first.inner_text().strip()
                if txt == str(target):
                    loc = temp_loc.first
                    if verbose:
                        print(f"    âœ… {target}ë²ˆ í˜ì´ì§€ ë§í¬ ë°œê²¬ (ì „ì²´ ê²€ìƒ‰)")
        except:
            pass

    # âœ… ë§í¬ê°€ ì—†ìœ¼ë©´ "ë‹¤ìŒ" ë²„íŠ¼ í´ë¦­ ì‹œë„ (10, 20, 30... ë„˜ì–´ê°ˆ ë•Œ)
    if loc is None:
        if verbose:
            print(f"    âš ï¸  {target}ë²ˆ í˜ì´ì§€ ë§í¬ê°€ ë³´ì´ì§€ ì•ŠìŒ, 'ë‹¤ìŒ' ë²„íŠ¼ ì‹œë„...")
        
        next_clicked = False
        # ì˜¬ë¦¬ë¸Œì˜ì˜ ì •í™•í•œ "ë‹¤ìŒ" ë²„íŠ¼ í´ë˜ìŠ¤
        for next_selector in [
            "a.pageing_next",  # âœ… ì˜¬ë¦¬ë¸Œì˜ "ë‹¤ìŒ" ë²„íŠ¼
            "a[class*='next']",
            "a[class*='Next']",
            "button.pageing_next",
            "a:has-text('ë‹¤ìŒ')",
            "a:has-text('â€º')", 
            "a:has-text('>')",
            "button:has-text('ë‹¤ìŒ')",
            "button:has-text('â€º')"
        ]:
            try:
                next_btn = page.locator(next_selector)
                if next_btn.count() > 0:
                    if verbose:
                        print(f"    ğŸ‘‰ 'ë‹¤ìŒ' ë²„íŠ¼ ë°œê²¬! (selector: {next_selector})")
                    next_btn.first.click(timeout=2000)
                    page.wait_for_timeout(1500)
                    next_clicked = True
                    break
            except Exception as e:
                if verbose:
                    print(f"    âš ï¸  {next_selector} í´ë¦­ ì‹¤íŒ¨: {e}")
                continue
        
        if not next_clicked:
            if verbose:
                print(f"    âŒ 'ë‹¤ìŒ' ë²„íŠ¼ë„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        # "ë‹¤ìŒ" ë²„íŠ¼ í´ë¦­ í›„ ì¶©ë¶„íˆ ëŒ€ê¸°
        if verbose:
            print(f"    â³ í˜ì´ì§€ ë²ˆí˜¸ ë¡œë”© ëŒ€ê¸° ì¤‘ (5ì´ˆ)...")
        page.wait_for_timeout(5000)  # 1500ms â†’ 5000ms
        
        # í˜ì´ì§€ë„¤ì´ì…˜ ë‹¤ì‹œ ë³´ì´ê²Œ
        scroll_to_pagination_bottom(page)
        page.wait_for_timeout(1000)
        
        try:
            # data-page-no ì†ì„±ìœ¼ë¡œ ë‹¤ì‹œ ì°¾ê¸°
            temp_loc = page.locator(f"[data-page-no='{target}']")
            if temp_loc.count() > 0:
                loc = temp_loc.first
                if verbose:
                    print(f"    âœ… 'ë‹¤ìŒ' ë²„íŠ¼ í´ë¦­ í›„ {target}ë²ˆ í˜ì´ì§€ ë°œê²¬! (data-page-no)")
        except:
            pass
        
        if loc is None:
            try:
                temp_loc = page.locator("div.pageing a").filter(has_text=re.compile(rf"^{target}$"))
                if temp_loc.count() > 0:
                    txt = temp_loc.first.inner_text().strip()
                    if txt == str(target):
                        loc = temp_loc.first
                        if verbose:
                            print(f"    âœ… 'ë‹¤ìŒ' ë²„íŠ¼ í´ë¦­ í›„ {target}ë²ˆ í˜ì´ì§€ ë°œê²¬!")
            except:
                pass
        
        if loc is None:
            if verbose:
                print(f"    âŒ 'ë‹¤ìŒ' ë²„íŠ¼ í´ë¦­ í›„ì—ë„ {target}ë²ˆ í˜ì´ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False

    before_href = None
    try:
        before_href = page.locator('a[href*="getGoodsDetail.do"]').first.get_attribute("href")
    except:
        pass

    try:
        if verbose:
            print(f"    ğŸ‘† {target}ë²ˆ í˜ì´ì§€ í´ë¦­ ì¤‘...")
        
        # JavaScriptë¡œ ì§ì ‘ í´ë¦­ (ë” ì•ˆì •ì )
        page.evaluate(f"""
            const elem = document.querySelector('[data-page-no="{target}"]');
            if (elem) {{
                elem.scrollIntoView({{behavior: 'smooth', block: 'center'}});
                elem.click();
            }}
        """)
        page.wait_for_timeout(1000)
        
    except Exception as e:
        if verbose:
            print(f"    âŒ {target}ë²ˆ í˜ì´ì§€ í´ë¦­ ì‹¤íŒ¨: {e}")
        return False

    if verbose:
        print(f"    â³ í˜ì´ì§€ ë¡œë”© ëŒ€ê¸° ì¤‘...")
    for wait_count in range(30):
        page.wait_for_timeout(250)
        try:
            now_href = page.locator('a[href*="getGoodsDetail.do"]').first.get_attribute("href")
            if before_href and now_href and now_href != before_href:
                if verbose:
                    print(f"    âœ… í˜ì´ì§€ ë¡œë”© ì™„ë£Œ ({wait_count * 0.25:.1f}ì´ˆ ì†Œìš”)")
                return True
        except:
            pass

    if verbose:
        print(f"    âš ï¸  í˜ì´ì§€ ë³€í™” í™•ì¸ ë¶ˆê°€, ê³„ì† ì§„í–‰...")
    return True

def scrape_all(headless=True, verbose=True):
    """ëª¨ë“  í˜ì´ì§€ í¬ë¡¤ë§"""
    df, seen = load_existing()
    
    if verbose:
        print("="*60)
        print("ğŸš€ ì˜¬ë¦¬ë¸Œì˜ í¬ë¡¤ëŸ¬ ì‹œì‘")
        print("="*60)
        print(f"ì¹´í…Œê³ ë¦¬: {CATEGORY}")
        print(f"ì‹œì‘ URL: {START_URL}")
        print(f"Headless ëª¨ë“œ: {headless}")
        if len(df) > 0:
            print(f"ê¸°ì¡´ ë°ì´í„°: {len(df)}ê°œ ì œí’ˆ ë°œê²¬")
        print("="*60)

    with sync_playwright() as p:
        browser = p.chromium.launch(headless=headless)
        page = browser.new_page(
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120 Safari/537.36",
            locale="ko-KR"
        )

        if verbose:
            print("\nğŸŒ í˜ì´ì§€ ë¡œë”© ì¤‘...")
        page.goto(START_URL, wait_until="networkidle")
        
        if verbose:
            print("âš™ï¸  VIEW 48 ì„¤ì • ì‹œë„...")
        click_view_48(page)
        if verbose:
            print("  âœ… VIEW 48 ì„¤ì • ì™„ë£Œ (ì—†ìœ¼ë©´ ê±´ë„ˆëœ€)")

        page_idx = 0

        while True:
            page_idx += 1
            if verbose:
                print(f"\n{'='*60}")
                print(f"ğŸ“„ [í˜ì´ì§€ {page_idx}] í¬ë¡¤ë§ ì‹œì‘")
                print(f"{'='*60}")

            try:
                cur = get_current_page_num(page)
                if verbose:
                    print(f"ğŸ“ í˜„ì¬ í˜ì´ì§€ ë²ˆí˜¸: {cur}ë²ˆ")
            except Exception as e:
                if verbose:
                    print(f"âš ï¸  í˜ì´ì§€ ë²ˆí˜¸ í™•ì¸ ì‹¤íŒ¨: {e}")
                cur = page_idx

            scroll_for_loading_products(page, verbose=verbose)

            if verbose:
                print("ğŸ“‹ ì œí’ˆ ì •ë³´ ì¶”ì¶œ ì¤‘...")
            rows = extract_products_on_page(page, seen, verbose=verbose)
            
            if rows:
                new_df = pd.DataFrame(rows)
                df = pd.concat([df, new_df], ignore_index=True)

            df = df.drop_duplicates(subset=["product_url"]).reset_index(drop=True)
            df["product_id"] = range(1, len(df) + 1)
            df = df[["product_id", "category", "brand", "product_name", "product_url"]]
            df.to_csv(OUT_CSV, index=False, encoding="utf-8-sig")
            
            if verbose:
                print(f"\nğŸ’¾ ì €ì¥ ì™„ë£Œ!")
                print(f"  â””â”€ ì´ë²ˆ í˜ì´ì§€ ì‹ ê·œ ì œí’ˆ: {len(rows)}ê°œ")
                print(f"  â””â”€ ì´ ëˆ„ì  ì œí’ˆ ìˆ˜: {len(df)}ê°œ")
                print(f"  â””â”€ ì €ì¥ íŒŒì¼: {OUT_CSV}")
            else:
                print(f"[Page {cur}] new={len(rows)} total={len(df)}")

            nxt = cur + 1
            if verbose:
                print(f"\nâ¡ï¸  ë‹¤ìŒ í˜ì´ì§€ ì´ë™ ì‹œë„ ({cur}ë²ˆ â†’ {nxt}ë²ˆ)...")
            
            moved = click_page_number(page, nxt, verbose=verbose)
            if not moved:
                if verbose:
                    print("\n" + "="*60)
                    print("âœ… ëª¨ë“  í˜ì´ì§€ í¬ë¡¤ë§ ì™„ë£Œ!")
                    print(f"  â””â”€ ë§ˆì§€ë§‰ í˜ì´ì§€: {cur}ë²ˆ")
                    print(f"  â””â”€ ì´ ì œí’ˆ ìˆ˜: {len(df)}ê°œ")
                    print("="*60)
                else:
                    print(f"[Done] ë‹¤ìŒ í˜ì´ì§€ ë²ˆí˜¸ë¥¼ ëª» ì°¾ì•„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break

            time.sleep(POLITE_SLEEP_SEC)

        browser.close()

    if verbose:
        print(f"\nâœ… ìµœì¢… ì™„ë£Œ: {OUT_CSV} / rows={len(df)}")
    return df

if __name__ == "__main__":
    import sys
    
    headless_mode = "--headless" in sys.argv if len(sys.argv) > 1 else False
    verbose_mode = "--quiet" not in sys.argv
    
    print("\nğŸ’¡ íŒ: ë¸Œë¼ìš°ì €ë¥¼ ë³´ë ¤ë©´ headless=Falseë¡œ ì„¤ì •í•˜ì„¸ìš”")
    print("   í¬ë¡¤ë§ ì§„í–‰ ìƒí™©ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!\n")
    
    df2 = scrape_all(headless=headless_mode, verbose=verbose_mode)
    
    print("\n" + "="*60)
    print("ğŸ“‹ ìµœì¢… ê²°ê³¼ ìš”ì•½")
    print("="*60)
    print(df2.head(10))
    print(f"\nğŸ“Š ì´ ìƒí’ˆ ìˆ˜: {len(df2)}ê°œ")
    print(f"ğŸ’¾ ì €ì¥ íŒŒì¼: {OUT_CSV}")
    print("="*60)