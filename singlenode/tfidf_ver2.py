"""
ë‹¨ì¼ ë…¸ë“œ(ì œí’ˆ) GNN ê¸°ë°˜ í™”ì¥í’ˆ ì¶”ì²œì‹œìŠ¤í…œ (BPR + Negative Sampling + Skin->Ingredient Profile)

- ë…¸ë“œ(ì œí’ˆ) í”¼ì²˜: ì¹´í…Œê³ ë¦¬ one-hot + ë¸Œëœë“œ one-hot + ì„±ë¶„ TF-IDF -> SVD + í”¼ë¶€íƒ€ì…ë³„ í‰ê· í‰ì (ê²°ì¸¡ì€ global meanìœ¼ë¡œ)
- ì—£ì§€: ì„±ë¶„ ì„ë² ë”©(SVD) ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ + ê°™ì€ ì¹´í…Œê³ ë¦¬
- í•™ìŠµ: BPR loss (pos: rating>=4, neg: userê°€ trainì—ì„œ ì•ˆ ë³¸ ì•„ì´í…œ ëœë¤)
- ì¶”ì²œ/í‰ê°€: GNN ì ìˆ˜ + (í”¼ë¶€íƒ€ì… ì„±ë¶„ì·¨í–¥ ì ìˆ˜) í•˜ì´ë¸Œë¦¬ë“œ
  * ë¦¬ë·° í…ìŠ¤íŠ¸/ê°ì„±/ê¸¸ì´ ì•ˆ ì”€. ì˜¤ì§ í”¼ë¶€íƒ€ì…+í‰ì ë§Œ ì‚¬ìš©.
"""

import os
import ast
import warnings
warnings.filterwarnings("ignore")

import numpy as np
import pandas as pd

import torch
import torch.nn as nn
import torch.nn.functional as F

from torch_geometric.data import Data
from torch_geometric.nn import GCNConv

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer, normalize
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import TruncatedSVD
from sklearn.metrics import roc_auc_score, average_precision_score
import joblib


# -------------------------
# ì „ì—­ í•¨ìˆ˜ (pickle ì•ˆì „) âœ… lambda ê¸ˆì§€
# -------------------------
def identity(x):
    return x


# -------------------------
# ê³ ì • ì¹´í…Œê³ ë¦¬ 5ê°œ
# -------------------------
ALLOWED_CATEGORIES = [
    "ìŠ¤í‚¨/í† ë„ˆ",
    "ë¡œì…˜",
    "ì—ì„¼ìŠ¤/ì„¸ëŸ¼/ì•°í”Œ",
    "í¬ë¦¼",
    "ë¯¸ìŠ¤íŠ¸/ì˜¤ì¼"
]

SKIN_TYPES_ALL = ["ê±´ì„±", "ë¯¼ê°ì„±", "ë³µí•©ì„±", "ì•½ê±´ì„±", "ì§€ì„±", "íŠ¸ëŸ¬ë¸”ì„±", "ì¤‘ì„±"]
SKIN_TO_IDX = {s: i for i, s in enumerate(SKIN_TYPES_ALL)}


# =========================
# ëª¨ë¸
# =========================
class ProductGNN(nn.Module):
    def __init__(self, in_channels, hidden_channels=128, num_layers=3, user_feature_dim=8):
        super().__init__()
        self.convs = nn.ModuleList()
        self.convs.append(GCNConv(in_channels, hidden_channels))
        for _ in range(num_layers - 1):
            self.convs.append(GCNConv(hidden_channels, hidden_channels))

        combined_dim = user_feature_dim + hidden_channels
        self.predictor = nn.Sequential(
            nn.Linear(combined_dim, hidden_channels),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(hidden_channels, 1)
        )

    def forward(self, x, edge_index):
        for i, conv in enumerate(self.convs):
            x = conv(x, edge_index)
            if i < len(self.convs) - 1:
                x = F.relu(x)
                x = F.dropout(x, p=0.3, training=self.training)
        return x

    def score(self, x, edge_index, user_features, product_indices):
        """
        user_features: [B, 8]
        product_indices: [B]
        return: [B] raw scores
        """
        prod_emb = self.forward(x, edge_index)               # [N, hidden]
        sel = prod_emb[product_indices]                      # [B, hidden]
        combined = torch.cat([user_features, sel], dim=-1)   # [B, 8+hidden]
        return self.predictor(combined).squeeze(-1)          # [B]


# =========================
# ì¶”ì²œ ì‹œìŠ¤í…œ
# =========================
class SingleNodeGNNRecommender:
    def __init__(self, products_path, reviews_path, svd_dim=100, top_k_edges=15, debug=False):
        self.debug = debug
        self.svd_dim = svd_dim
        self.top_k_edges = top_k_edges

        # í•˜ì´ë¸Œë¦¬ë“œ ê°€ì¤‘ì¹˜ (GNN vs ì„±ë¶„ì·¨í–¥)
        self.alpha = 0.7  # 0.7*GNN + 0.3*skin->ingredient (ì›í•˜ë©´ ë°”ê¿”)

        print("ğŸ“š ë°ì´í„° ë¡œë”© ì¤‘...")
        self.products_df = pd.read_csv(products_path)
        self.reviews_df = pd.read_csv(reviews_path, encoding="utf-8-sig")

        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"ğŸ–¥ï¸  ë””ë°”ì´ìŠ¤: {self.device}")

        # encoders
        self.product_encoder = LabelEncoder()
        self.category_encoder = LabelEncoder()
        self.brand_encoder = LabelEncoder()
        self.user_encoder = LabelEncoder()
        self.mlb_ingredients = MultiLabelBinarizer()

        self._preprocess_data()
        self._build_graph()

        # í”¼ë¶€íƒ€ì… ì„±ë¶„ ì·¨í–¥ ë²¡í„°ëŠ” train split ì´í›„ì— ë§Œë“¤ ìˆ˜ ìˆì–´ì„œ,
        # train_bpr ì•ˆì—ì„œ ë§Œë“¤ì–´ì¤„ ê±°ì„.

    # ---------- ì „ì²˜ë¦¬ ----------
    def _preprocess_data(self):
        print("ğŸ”§ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")

        def parse_ingredients(x):
            if not isinstance(x, str):
                return []
            try:
                x = x.replace("â€™", "'").replace("â€˜", "'")
                x = x.replace('â€œ', '"').replace('â€', '"')
                return ast.literal_eval(x)
            except:
                return []

        self.products_df["ingredients_list"] = self.products_df["ingredients"].apply(parse_ingredients)

        # ìŠ¤í‚¨íƒ€ì… ê²°ì¸¡ ì²˜ë¦¬
        if self.reviews_df["user_keywords"].isna().any():
            na_count = int(self.reviews_df["user_keywords"].isna().sum())
            print(f"âš ï¸  í”¼ë¶€íƒ€ì… ê²°ì¸¡ê°’ {na_count}ê°œ -> 'ì•Œ ìˆ˜ ì—†ìŒ'")
            self.reviews_df["user_keywords"] = self.reviews_df["user_keywords"].fillna("ì•Œ ìˆ˜ ì—†ìŒ")

        self.reviews_df["skin_types"] = self.reviews_df["user_keywords"].apply(
            lambda x: [t.strip() for t in str(x).split("|")]
        )
        self.reviews_df["rating_normalized"] = self.reviews_df["user_rating"] / 5.0

        # ì¸ì½”ë”©
        self.products_df["product_encoded"] = self.product_encoder.fit_transform(self.products_df["product_id"])
        self.products_df["category_encoded"] = self.category_encoder.fit_transform(self.products_df["category"])
        self.products_df["brand_encoded"] = self.brand_encoder.fit_transform(self.products_df["brand"])
        self.reviews_df["user_encoded"] = self.user_encoder.fit_transform(self.reviews_df["user_id"])

        product_to_encoded = dict(zip(self.products_df["product_id"], self.products_df["product_encoded"]))
        self.reviews_df["product_encoded"] = self.reviews_df["product_id"].map(product_to_encoded)

        # ì„±ë¶„ vocab í™•ì¸ìš© (ë©€í‹°í•«)
        all_ingredients = self.products_df["ingredients_list"].tolist()
        self.ingredient_multihot = self.mlb_ingredients.fit_transform(all_ingredients)

        # âœ… ì„±ë¶„ TF-IDF (lambda ì—†ì´!)
        self.tfidf_vectorizer = TfidfVectorizer(
            tokenizer=identity,
            preprocessor=identity,
            token_pattern=None,
            lowercase=False
        )
        self.ingredient_tfidf = self.tfidf_vectorizer.fit_transform(self.products_df["ingredients_list"])

        # âœ… TF-IDF -> SVD (ë…¸ë“œ í”¼ì²˜ + ì„±ë¶„ ìœ ì‚¬ë„)
        self.svd = TruncatedSVD(n_components=self.svd_dim, random_state=42)
        ing_svd = self.svd.fit_transform(self.ingredient_tfidf)     # (N, svd_dim)
        self.ingredient_svd = normalize(ing_svd)                    # (N, svd_dim), cosine=dot

        print(f"âœ… ì œí’ˆ ìˆ˜: {len(self.product_encoder.classes_)}")
        print(f"âœ… ì‚¬ìš©ì ìˆ˜: {len(self.user_encoder.classes_)}")
        print(f"âœ… ë¦¬ë·° ìˆ˜: {len(self.reviews_df)}")
        print(f"âœ… ì¹´í…Œê³ ë¦¬ ìˆ˜: {len(self.category_encoder.classes_)}")
        print(f"âœ… ë¸Œëœë“œ ìˆ˜: {len(self.brand_encoder.classes_)}")
        print(f"âœ… ì„±ë¶„ vocab ìˆ˜: {self.ingredient_multihot.shape[1]}")
        print(f"âœ… ì„±ë¶„ TF-IDF shape: {self.ingredient_tfidf.shape}")
        print(f"âœ… ì„±ë¶„ SVD shape: {self.ingredient_svd.shape}")

        # skin_type_to_vector (ì›í•«)
        self.skin_type_to_vector = {st: [1.0 if x == st else 0.0 for x in SKIN_TYPES_ALL] for st in SKIN_TYPES_ALL}

    # ---------- ê·¸ë˜í”„ ----------
    def _build_graph(self):
        print("ğŸ”¨ ê·¸ë˜í”„ êµ¬ì¶• ì¤‘...")

        # category one-hot
        num_categories = len(self.category_encoder.classes_)
        category_onehot = np.eye(num_categories)[self.products_df["category_encoded"].values]

        # brand one-hot
        num_brands = len(self.brand_encoder.classes_)
        brand_onehot = np.eye(num_brands)[self.products_df["brand_encoded"].values]

        # âœ… skin-typeë³„ ì œí’ˆ í‰ê·  í‰ì  (ê²°ì¸¡ì€ 1.0 ë§ê³  global meanìœ¼ë¡œ ì±„ì›€)
        global_mean_by_skin = {}
        for st in SKIN_TYPES_ALL:
            st_rows = self.reviews_df[self.reviews_df["skin_types"].apply(lambda x: st in x)]
            if len(st_rows) > 0:
                global_mean_by_skin[st] = float(st_rows["user_rating"].mean() / 5.0)
            else:
                global_mean_by_skin[st] = 0.6  # ì•ˆì „ë¹µ(=3ì ) ëŠë‚Œ

        skin_ratings = np.zeros((len(self.products_df), len(SKIN_TYPES_ALL)), dtype=np.float32)
        for idx, product_id in enumerate(self.products_df["product_id"].values):
            pr = self.reviews_df[self.reviews_df["product_id"] == product_id]
            for i, st in enumerate(SKIN_TYPES_ALL):
                st_reviews = pr[pr["skin_types"].apply(lambda x: st in x)]
                if len(st_reviews) > 0:
                    skin_ratings[idx, i] = float(st_reviews["user_rating"].mean() / 5.0)
                else:
                    # âœ… ê²°ì¸¡ì€ global meanìœ¼ë¡œ
                    skin_ratings[idx, i] = float(global_mean_by_skin[st])

        # âœ… ë…¸ë“œ í”¼ì²˜
        node_features = np.concatenate([category_onehot, brand_onehot, self.ingredient_svd, skin_ratings], axis=1)
        self.node_features = torch.FloatTensor(node_features)

        # ì—£ì§€ ìƒì„±
        print("ğŸ”— ì œí’ˆ ê°„ ìœ ì‚¬ë„ ê¸°ë°˜ ì—£ì§€ ìƒì„± ì¤‘...")
        edges = self._compute_edges(top_k=self.top_k_edges)
        self.edge_index = torch.LongTensor(edges)

        self.data = Data(x=self.node_features, edge_index=self.edge_index)
        print("âœ… ê·¸ë˜í”„ êµ¬ì¶• ì™„ë£Œ")
        print(f"   - ë…¸ë“œ ìˆ˜: {self.data.x.size(0)}")
        print(f"   - í”¼ì²˜ ì°¨ì›: {self.data.x.size(1)}")
        print(f"   - ì—£ì§€ ìˆ˜: {self.data.edge_index.size(1)}")

    def _compute_edges(self, top_k=15):
        sim = self.ingredient_svd @ self.ingredient_svd.T  # (N,N)
        n = sim.shape[0]
        edges = []

        # 1) ì„±ë¶„ ìœ ì‚¬ë„ top-k
        for i in range(n):
            s = sim[i].copy()
            s[i] = -1
            top = np.argsort(s)[-top_k:]
            for j in top:
                if s[j] > 0.1:
                    edges.append((i, j))

        # 2) ê°™ì€ ì¹´í…Œê³ ë¦¬ ì•½í•˜ê²Œ ì—°ê²°
        for cat in self.products_df["category"].unique():
            ids = self.products_df[self.products_df["category"] == cat]["product_encoded"].values
            if len(ids) > 1:
                for a in range(len(ids)):
                    for b in range(a + 1, min(a + 6, len(ids))):
                        edges.append((ids[a], ids[b]))
                        edges.append((ids[b], ids[a]))

        edges = list(set(edges))
        if len(edges) == 0:
            edges = [(i, i + 1) for i in range(n - 1)] + [(i + 1, i) for i in range(n - 1)]

        return np.array(edges).T

    # ---------- ìœ ì € í”„ë¡œí•„ ----------
    def _build_user_profiles(self, df_train):
        """
        user_encoded -> 8ì°¨ì› (skin 7 + mean rating 1)
        """
        user_feat = {}
        grouped = df_train.groupby("user_encoded")

        for u, g in grouped:
            vec = np.zeros(7, dtype=np.float32)
            for skins in g["skin_types"].values:
                for st in skins:
                    if st in SKIN_TO_IDX:
                        vec[SKIN_TO_IDX[st]] += 1.0

            s = vec.sum()
            if s > 0:
                vec = vec / s
            else:
                vec = np.ones(7, dtype=np.float32) / 7.0

            r = float(g["rating_normalized"].mean())
            if np.isnan(r):
                r = 0.8

            user_feat[int(u)] = np.concatenate([vec, [r]]).astype(np.float32)
        return user_feat

    # =========================
    # âœ… í”¼ë¶€íƒ€ì… ì„±ë¶„ ì·¨í–¥ ë²¡í„° (ë©”íƒ€íŒ¨ìŠ¤ í•µì‹¬!)
    # =========================
    def _build_skin_pref_vectors(self, df_train, pos_threshold=4):
        """
        skin -> ingredient preference vector (svd_dim)
        - df_trainì—ì„œ í”¼ë¶€íƒ€ì… st í¬í•¨ & rating>=pos_threshold ì¸ ì œí’ˆë“¤ì˜ ingredient_svd ê°€ì¤‘í•©
        - ê°€ì¤‘ì¹˜ëŠ” (rating-3) ì‚¬ìš© (4ì =1, 5ì =2)
        - normalizeí•´ì„œ cosine ë¹„êµ ê°€ëŠ¥í•˜ê²Œ í•¨
        """
        skin_pref = np.zeros((len(SKIN_TYPES_ALL), self.svd_dim), dtype=np.float32)

        # ê¸ì • ìƒ˜í”Œë§Œ
        pos = df_train[df_train["user_rating"] >= pos_threshold].copy()

        for _, row in pos.iterrows():
            p = int(row["product_encoded"])
            r = float(row["user_rating"])
            w = max(0.0, r - 3.0)  # 4->1, 5->2
            if w == 0:
                continue

            skins = row["skin_types"]
            for st in skins:
                if st in SKIN_TO_IDX:
                    skin_pref[SKIN_TO_IDX[st]] += (w * self.ingredient_svd[p]).astype(np.float32)

        # normalize (í–‰ ë‹¨ìœ„)
        skin_pref = normalize(skin_pref)
        self.skin_pref_matrix = skin_pref  # (7, svd_dim)

        # ë‹¨ì¼ skin_type ë°”ë¡œ ë½‘ê²Œ dictë„
        self.skin_pref_vec = {st: self.skin_pref_matrix[SKIN_TO_IDX[st]] for st in SKIN_TYPES_ALL}

        print("âœ… í”¼ë¶€íƒ€ì… ì„±ë¶„ ì·¨í–¥ ë²¡í„° êµ¬ì¶• ì™„ë£Œ:", self.skin_pref_matrix.shape)

    # =========================
    # âœ… BPR í•™ìŠµ
    # =========================
    def train_bpr(self, epochs=50, hidden_channels=128, lr=0.001,
                  batch_size=1024, steps_per_epoch=200, pos_threshold=4):
        print(f"\nğŸ“ BPR í•™ìŠµ ì‹œì‘ (epochs={epochs}, steps/epoch={steps_per_epoch})")

        train_reviews, test_reviews = train_test_split(self.reviews_df, test_size=0.2, random_state=42)
        self.train_reviews = train_reviews.reset_index(drop=True)
        self.test_reviews = test_reviews.reset_index(drop=True)

        # âœ… ì—¬ê¸°ì„œ í”¼ë¶€íƒ€ì… ì„±ë¶„ ì·¨í–¥ ë²¡í„° ë§Œë“¤ê¸° (ë¦¬ë·°í…ìŠ¤íŠ¸ ì•ˆì”€)
        self._build_skin_pref_vectors(self.train_reviews, pos_threshold=pos_threshold)

        in_channels = self.node_features.size(1)
        self.model = ProductGNN(in_channels=in_channels, hidden_channels=hidden_channels, num_layers=3).to(self.device)
        optimizer = torch.optim.Adam(self.model.parameters(), lr=lr, weight_decay=1e-5)

        self.data = self.data.to(self.device)

        user_profiles = self._build_user_profiles(self.train_reviews)

        user_seen = (
            self.train_reviews.groupby("user_encoded")["product_encoded"]
            .apply(lambda s: set(s.dropna().astype(int).tolist()))
            .to_dict()
        )

        train_pos = self.train_reviews[self.train_reviews["user_rating"] >= pos_threshold]
        user_pos = (
            train_pos.groupby("user_encoded")["product_encoded"]
            .apply(lambda s: list(set(s.dropna().astype(int).tolist())))
            .to_dict()
        )

        n_items = len(self.products_df)
        users = []
        for u in user_pos.keys():
            seen = user_seen.get(u, set())
            if len(user_pos[u]) > 0 and len(seen) < n_items:
                users.append(int(u))

        if len(users) == 0:
            raise RuntimeError("BPR í•™ìŠµ ë¶ˆê°€: positive ìœ ì €ê°€ ì—†ê±°ë‚˜, ëª¨ë“  ì•„ì´í…œì„ ë³¸ ìœ ì €ë¿ì„.")

        best_recall = -1.0
        os.makedirs("singlenode", exist_ok=True)

        for epoch in range(1, epochs + 1):
            self.model.train()
            losses = []

            for _ in range(steps_per_epoch):
                bu = np.random.choice(users, size=min(batch_size, len(users)), replace=False)

                pos_items, neg_items, u_feats = [], [], []
                for u in bu:
                    p = int(np.random.choice(user_pos[u]))
                    seen = user_seen.get(u, set())

                    # neg: seenì— ì—†ëŠ” ì•„ì´í…œ ìƒ˜í”Œ
                    while True:
                        n = int(np.random.randint(0, n_items))
                        if n not in seen:
                            break

                    pos_items.append(p)
                    neg_items.append(n)
                    u_feats.append(user_profiles[u])

                u_feats = torch.FloatTensor(np.stack(u_feats)).to(self.device)
                pos_idx = torch.LongTensor(pos_items).to(self.device)
                neg_idx = torch.LongTensor(neg_items).to(self.device)

                optimizer.zero_grad()
                s_pos = self.model.score(self.data.x, self.data.edge_index, u_feats, pos_idx)
                s_neg = self.model.score(self.data.x, self.data.edge_index, u_feats, neg_idx)

                loss = -torch.log(torch.sigmoid(s_pos - s_neg) + 1e-8).mean()
                loss.backward()
                optimizer.step()
                losses.append(loss.item())

            if epoch % 5 == 0:
                metrics = self.evaluate(k=5, max_users=1500)
                print(f"Epoch {epoch}/{epochs} | BPR Loss: {np.mean(losses):.4f} | "
                      f"AUC: {metrics['AUC']:.4f} | Recall@5: {metrics['Recall@5']:.4f} | "
                      f"AP: {metrics['AP']:.4f} | NDCG@5: {metrics['NDCG@5']:.4f}")

                if metrics["Recall@5"] > best_recall:
                    best_recall = metrics["Recall@5"]
                    torch.save(self.model.state_dict(), "singlenode/best_single_gnn_model_bpr.pt")

        print(f"\nâœ… BPR í•™ìŠµ ì™„ë£Œ! best Recall@5={best_recall:.4f}")
        self.model.load_state_dict(torch.load("singlenode/best_single_gnn_model_bpr.pt", map_location=self.device))

    # =========================
    # âœ… ì§„ì§œ ì¶”ì²œ í‰ê°€ (í•˜ì´ë¸Œë¦¬ë“œ ìŠ¤ì½”ì–´ ë°˜ì˜)
    # =========================
    def evaluate(self, k=5, max_users=2000, seed=42):
        assert hasattr(self, "model"), "ëª¨ë¸ í•™ìŠµ í›„ evaluate í˜¸ì¶œí•´ì•¼ í•¨"
        assert hasattr(self, "train_reviews") and hasattr(self, "test_reviews"), "train_bpr ë¨¼ì € ëŒë ¤ì•¼ í•¨"
        assert hasattr(self, "skin_pref_matrix"), "skin_pref_matrixê°€ ì—†ìŒ (train_bprì—ì„œ ìƒì„±ë¨)"

        train_reviews = self.train_reviews
        test_reviews = self.test_reviews

        rng = np.random.default_rng(seed)
        self.model.eval()

        user_train_seen = (
            train_reviews.groupby("user_encoded")["product_encoded"]
            .apply(lambda s: set(s.dropna().astype(int).tolist()))
            .to_dict()
        )

        test_pos = test_reviews[test_reviews["user_rating"] >= 4].copy()
        user_test_pos = (
            test_pos.groupby("user_encoded")["product_encoded"]
            .apply(lambda s: set(s.dropna().astype(int).tolist()))
            .to_dict()
        )

        users = list(user_test_pos.keys())
        if len(users) == 0:
            return {"AUC": 0.5, "Recall@5": 0.0, "AP": 0.0, "NDCG@5": 0.0}

        if len(users) > max_users:
            users = rng.choice(users, size=max_users, replace=False).tolist()

        user_profiles = self._build_user_profiles(train_reviews)

        all_items = torch.arange(len(self.products_df)).to(self.device)
        recalls, ndcgs, aucs, aps = [], [], [], []

        # ingredient ê¸°ë°˜ ì ìˆ˜ ë¯¸ë¦¬ ê³„ì‚°ìš©
        ing_mat = self.ingredient_svd  # (N, svd_dim)

        for u in users:
            pos_items = user_test_pos.get(u, set())
            if len(pos_items) == 0:
                continue

            seen = user_train_seen.get(u, set())
            if u not in user_profiles:
                continue

            uf = user_profiles[int(u)]  # (8,)
            skin_probs = uf[:7]         # (7,)
            user_feature = torch.FloatTensor([uf]).to(self.device)  # [1,8]

            # âœ… ìœ ì €ì˜ ì„±ë¶„ì·¨í–¥ ë²¡í„°: skin_probs @ skin_pref_matrix
            user_pref_vec = skin_probs @ self.skin_pref_matrix  # (svd_dim,)
            # cosine=dot (ë‘˜ ë‹¤ normalize ëœ ë°©í–¥ì„±ì´ë¼ ì•ˆì •ì )
            content_scores = (user_pref_vec @ ing_mat.T).astype(np.float32)  # (N,)

            with torch.no_grad():
                u_rep = user_feature.repeat(len(self.products_df), 1)
                gnn_scores = self.model.score(self.data.x, self.data.edge_index, u_rep, all_items).detach().cpu().numpy()

            # âœ… í•˜ì´ë¸Œë¦¬ë“œ
            scores = self.alpha * gnn_scores + (1 - self.alpha) * content_scores

            if len(seen) > 0:
                scores[np.array(list(seen), dtype=int)] = -np.inf

            if np.isneginf(scores).all():
                continue

            topk = np.argsort(scores)[-k:][::-1]
            hits = sum([1 for i in topk if i in pos_items])
            recall = hits / min(k, len(pos_items))
            recalls.append(recall)

            rel = np.array([1.0 if i in pos_items else 0.0 for i in topk], dtype=np.float32)
            dcg = np.sum(rel / np.log2(np.arange(2, k + 2)))
            ideal = np.sort(rel)[::-1]
            idcg = np.sum(ideal / np.log2(np.arange(2, k + 2)))
            ndcg = float(dcg / idcg) if idcg > 0 else 0.0
            ndcgs.append(ndcg)

            valid_mask = ~np.isneginf(scores)
            valid_scores = scores[valid_mask]
            valid_items = np.where(valid_mask)[0]
            y_true = np.array([1 if i in pos_items else 0 for i in valid_items], dtype=int)

            if y_true.sum() > 0 and y_true.sum() < len(y_true):
                try:
                    aucs.append(roc_auc_score(y_true, valid_scores))
                except:
                    pass
                try:
                    aps.append(average_precision_score(y_true, valid_scores))
                except:
                    pass

        return {
            "AUC": float(np.mean(aucs)) if len(aucs) else 0.5,
            "Recall@5": float(np.mean(recalls)) if len(recalls) else 0.0,
            "AP": float(np.mean(aps)) if len(aps) else 0.0,
            "NDCG@5": float(np.mean(ndcgs)) if len(ndcgs) else 0.0
        }

    # =========================
    # ì¶”ì²œ (í•˜ì´ë¸Œë¦¬ë“œ)
    # =========================
    def recommend(self, skin_type, category=None, favorite_product_id=None, top_n=5):
        assert hasattr(self, "skin_pref_vec"), "skin_pref_vecê°€ ì—†ìŒ (train_bpr ë¨¼ì € ëŒë ¤ì•¼ í•¨)"

        if category is not None and category != "ì „ì²´":
            if category not in ALLOWED_CATEGORIES:
                raise ValueError(f"categoryëŠ” ë‹¤ìŒ ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•¨: {ALLOWED_CATEGORIES} (ë˜ëŠ” None/'ì „ì²´')")

        self.model.eval()

        # user feature(8): skin one-hot + rating_feat(ìƒìˆ˜)
        skin_vector = self.skin_type_to_vector.get(skin_type, [1/7] * 7)
        user_feature_1 = torch.FloatTensor([skin_vector + [0.8]]).to(self.device)  # [1,8]

        all_items = torch.arange(len(self.products_df)).to(self.device)

        with torch.no_grad():
            u_rep = user_feature_1.repeat(len(self.products_df), 1)
            gnn_scores = self.model.score(self.data.x, self.data.edge_index, u_rep, all_items).detach().cpu().numpy()

        # âœ… í”¼ë¶€íƒ€ì… ì„±ë¶„ì·¨í–¥ ì ìˆ˜
        pref = self.skin_pref_vec.get(skin_type, np.zeros(self.svd_dim, dtype=np.float32))
        content_scores = (pref @ self.ingredient_svd.T).astype(np.float32)  # (N,)

        # âœ… í•˜ì´ë¸Œë¦¬ë“œ
        scores = self.alpha * gnn_scores + (1 - self.alpha) * content_scores

        # ì„ í˜¸ ì œí’ˆ ìœ ì‚¬ë„ ì¶”ê°€(ì„ íƒ)
        if favorite_product_id and favorite_product_id in self.products_df["product_id"].values:
            fav_encoded = int(self.products_df[self.products_df["product_id"] == favorite_product_id]["product_encoded"].values[0])
            fav_vec = self.ingredient_svd[fav_encoded].reshape(1, -1)
            sim = (fav_vec @ self.ingredient_svd.T).ravel().astype(np.float32)
            scores = 0.7 * scores + 0.3 * sim

        # ì¹´í…Œê³ ë¦¬ í•„í„°
        if category and category != "ì „ì²´":
            mask = (self.products_df["category"] == category).values
            if mask.sum() == 0:
                return []
            scores[~mask] = -np.inf
            if np.isneginf(scores).all():
                return []

        top_idx = np.argsort(scores)[-top_n:][::-1]

        recs = []
        for idx in top_idx:
            p = self.products_df.iloc[int(idx)]
            recs.append({
                "product_name": p["product_name"],
                "brand": p["brand"],
                "category": p["category"],
                "rating": float(p.get("product_rating", np.nan)),
                "predicted_score": float(scores[int(idx)]),
                "main_ingredients": p["ingredients_list"][:5],
            })
        return recs

    def print_recommendations(self, recs):
        print("\n" + "=" * 80)
        print("ğŸ ì¶”ì²œ ì œí’ˆ")
        print("=" * 80)
        for i, r in enumerate(recs, 1):
            print(f"\nã€ {i}. {r['product_name']} ã€‘")
            print(f"   ë¸Œëœë“œ: {r['brand']}")
            print(f"   ì¹´í…Œê³ ë¦¬: {r['category']}")
            if not np.isnan(r["rating"]):
                print(f"   í‰ì : â­ {r['rating']:.1f}")
            print(f"   ì˜ˆì¸¡ ì ìˆ˜: {r['predicted_score']:.3f}")
            print(f"   ì£¼ìš” ì„±ë¶„: {', '.join(r['main_ingredients'])}")
            print("-" * 80)

    # =========================
    # ì €ì¥/ë¡œë“œ
    # =========================
    def save(self, save_dir="singlenode"):
        os.makedirs(save_dir, exist_ok=True)

        torch.save({
            "model_state": self.model.state_dict(),
            "product_encoder": self.product_encoder,
            "category_encoder": self.category_encoder,
            "brand_encoder": self.brand_encoder,
            "user_encoder": self.user_encoder,
            "node_features": self.node_features,
            "edge_index": self.edge_index,
            "svd_dim": self.svd_dim,
            "top_k_edges": self.top_k_edges,
            "alpha": self.alpha,
            "skin_pref_matrix": self.skin_pref_matrix,  # numpy ê°€ëŠ¥(ì‘ìŒ)
        }, os.path.join(save_dir, "single_node_gnn_recommender_bpr.pt"))

        joblib.dump(self.tfidf_vectorizer, os.path.join(save_dir, "tfidf_vectorizer.joblib"))
        joblib.dump(self.svd, os.path.join(save_dir, "svd.joblib"))
        np.save(os.path.join(save_dir, "ingredient_svd.npy"), self.ingredient_svd)

        print("\nâœ… ì €ì¥ ì™„ë£Œ")


def main():
    recommender = SingleNodeGNNRecommender(
        products_path="singlenode/final_products.csv",
        reviews_path="singlenode/final_total_reviews.csv",
        svd_dim=100,
        top_k_edges=15
    )

    # âœ… BPR í•™ìŠµ
    recommender.train_bpr(
        epochs=50,
        hidden_channels=128,
        lr=0.001,
        batch_size=1024,
        steps_per_epoch=200,
        pos_threshold=4
    )

    # âœ… ìµœì¢… í‰ê°€
    print("\n" + "=" * 80)
    print("ğŸ“Š ìµœì¢… í‰ê°€ ê²°ê³¼")
    print("=" * 80)
    metrics = recommender.evaluate(k=5, max_users=2000)
    print(f"  AUC: {metrics['AUC']:.4f}")
    print(f"  Recall@5: {metrics['Recall@5']:.4f}")
    print(f"  AP: {metrics['AP']:.4f}")
    print(f"  NDCG@5: {metrics['NDCG@5']:.4f}")
    print("=" * 80)

    # âœ… ì¶”ì²œ í…ŒìŠ¤íŠ¸
    print("\n\n" + "=" * 80)
    print("ğŸ’¡ ì¶”ì²œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    print("=" * 80)

    recs = recommender.recommend(
        skin_type="ë¯¼ê°ì„±",
        category="ì—ì„¼ìŠ¤/ì„¸ëŸ¼/ì•°í”Œ",
        favorite_product_id=None,
        top_n=5
    )
    recommender.print_recommendations(recs)

    recommender.save("singlenode")


if __name__ == "__main__":
    main()
