{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "654ef02b",
   "metadata": {},
   "source": [
    "### 제품명 정규화(brand명 제거까지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0e39cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 컬럼 개수: 11\n",
      "                                                     product_name              canonical_name                        product_key\n",
      "   [2025 어워즈] 아누아 피디알엔 히알루론산 캡슐 100 세럼 30mL (+리필30mL+크림10mL+패드2매)        피디알엔 히알루론산 캡슐 100 세럼          아누아__피디알엔 히알루론산 캡슐 100 세럼\n",
      "                  [1월올영픽/진정탄력] 차앤박 더마앤서 액티브 부스트 PDRN 앰플 30ml 더블기획     더마앤서 액티브 부스트 PDRN 앰플 더블       차앤박__더마앤서 액티브 부스트 PDRN 앰플 더블\n",
      "                     [단독/1+1] 메디힐 마데카소사이드 흔적 리페어 세럼 40+40ml 더블 기획        마데카소사이드 흔적 리페어 세럼 40          메디힐__마데카소사이드 흔적 리페어 세럼 40\n",
      "[2025 어워즈/미백천재앰플] 메디큐브 PDRN 핑크앰플 30ml 어워즈 기획 (+리필50ml+세럼1.5ml*5매)                   PDRN 핑크앰플                    메디큐브__PDRN 핑크앰플\n",
      "                          [1월올영픽/키링증정] 이니스프리 레티놀 시카 앰플 30ml 더블 기획                레티놀 시카 앰플 더블                이니스프리__레티놀 시카 앰플 더블\n",
      "               [2025 어워즈 1위] 토리든 다이브인 저분자 히알루론산 세럼 100ml 어워즈 한정기획           다이브인 저분자 히알루론산 세럼             토리든__다이브인 저분자 히알루론산 세럼\n",
      "             [1월올영픽/보습광채] 차앤박 프로폴리스 에너지 액티브 앰플 30ml 2입 기획 (+15ml)            프로폴리스 에너지 액티브 앰플              차앤박__프로폴리스 에너지 액티브 앰플\n",
      "               [2025 어워즈] 웰라쥬 리얼 히알루로닉 블루 100 앰플 75ml 더블 어워즈 한정기획       리얼 히알루로닉 블루 100 앰플 더블         웰라쥬__리얼 히알루로닉 블루 100 앰플 더블\n",
      "                   [1월 올영픽 한정기획] 아이오페 레티놀 슈퍼 바운스 세럼 30ml +25ml 기획               레티놀 슈퍼 바운스 세럼                아이오페__레티놀 슈퍼 바운스 세럼\n",
      "                     [1월 올영픽 한정기획] 아이오페 레티놀 레티젝션 세럼 30ml +25ml 기획                 레티놀 레티젝션 세럼                  아이오페__레티놀 레티젝션 세럼\n",
      "    [1월올영픽]성분에디터 실크펩타이드 EGF 하트핏 볼륨 리프팅 앰플 40ml 더블기획(+산리오캐릭터즈 파우치) 실크펩타이드 EGF 하트핏 볼륨 리프팅 앰플 더블 성분에디터__실크펩타이드 EGF 하트핏 볼륨 리프팅 앰플 더블\n",
      "[모공에센스] VT 리들샷 100 에센스 50ml 기획 (+리들샷300 1ml*3개+PDRN에센스 1.5ml*3ea)                 리들샷 100 에센스                    VT__리들샷 100 에센스\n",
      "                      [애니PICK][광채탄력] VT PDRN 에센스 30ml 기획 2종 (택 1)                    PDRN 에센스                       VT__PDRN 에센스\n",
      "                         [1월올영PICK] 브링그린 징크테카 트러블 세럼 (대용량/콜라보/기획)                 징크테카 트러블 세럼                  브링그린__징크테카 트러블 세럼\n",
      "              [트러블1등/단독기획] 파티온 노스카나인 트러블 세럼 50ml 기획(+15ml+마스크 1매)                노스카나인 트러블 세럼                  파티온__노스카나인 트러블 세럼\n",
      "                                       더마팩토리 나이아신아마이드 20% 세럼 30ml              나이아신아마이드 20 세럼              더마팩토리__나이아신아마이드 20 세럼\n",
      "                     [1월 올영픽/크림증정] 유세린 하이알루론 에피셀린 세럼 30ml 홈스테틱 기획          하이알루론 에피셀린 세럼 홈스테틱            유세린__하이알루론 에피셀린 세럼 홈스테틱\n",
      "                        [1월올영픽/수분 충전]아벤느 이드랑스 에센스-인-로션 200ml 2입기획               이드랑스 에센스 인 로션                 아벤느__이드랑스 에센스 인 로션\n",
      "                      [1월 올영픽] 피지오겔 사이언수티컬즈 데일리뮨 앰플 세럼 20ml 2입 기획          사이언수티컬즈 데일리뮨 앰플 세럼           피지오겔__사이언수티컬즈 데일리뮨 앰플 세럼\n",
      "                            [청담샵 화잘먹/속수분] 그린핑거 포레스트 피톤 시카 세럼 50ml          그린핑거 포레스트 피톤 시카 세럼           포레스트__그린핑거 포레스트 피톤 시카 세럼\n",
      "\n",
      "저장 완료: products_ingredients_final_essence_brandremoved_keepcols.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# =========================\n",
    "# 1) 정규화 패턴\n",
    "# =========================\n",
    "PROMO_PATTERNS = [\n",
    "    r\"\\[.*?\\]\",\n",
    "    r\"\\(.*?\\)\",\n",
    "    r\"(?i)\\bset\\b\",\n",
    "    r\"기획팩|기획세트|기획|한정기획|한정|증량기획|증량|리뉴얼|어워즈|올영픽|온라인몰\\s*단독기획|단독기획|단품\",\n",
    "    r\"더블\\s*기획|트리플\\s*기획|1\\+1|2\\+1|3\\+1\",\n",
    "    r\"증정|사은품|증정품|추가\\s*증정|리필|리필팩|대용량|미니|샘플|사은|특가|한정판\",\n",
    "    r\"\\d+\\s*종\\s*(?:중\\s*)?택\\s*1\",\n",
    "    r\"(?:\\d+\\s*종\\s*)?중\\s*택\\s*1\",\n",
    "    r\"\\d+\\s*입|[0-9]+\\s*개입|[0-9]+\\s*개\",\n",
    "    r\"(?:단품|기획|세트|본품|리필|증정품|사은품)(?:\\s*/\\s*(?:단품|기획|세트|본품|리필|증정품|사은품))*\\s*(?:중\\s*)?택\\s*1\",\n",
    "    r\"\\d+\\s*중\\s*택\\s*1\",\n",
    "    r\"\\b\\d+\\b$\",\n",
    "    r\"\\d+\\s*종\\b\",\n",
    "    r\"\\b세트\\b\",\n",
    "    r\"\\d+\\s*중\\s*택\\s*(?:1)?\",\n",
    "    r\"\\b택\\s*1\\b\",\n",
    "    r\"\\+.*$\",\n",
    "]\n",
    "\n",
    "VOLUME_PATTERNS = [\n",
    "    r\"\\d+(?:\\.\\d+)?\\s*(?:ml|mL|ML)\\b\",\n",
    "    r\"\\d+(?:\\.\\d+)?\\s*(?:g|G)\\b\",\n",
    "    r\"\\d+(?:\\.\\d+)?\\s*(?:oz|OZ)\\b\",\n",
    "]\n",
    "\n",
    "def normalize_product_name(raw_name: str) -> str:\n",
    "    if pd.isna(raw_name):\n",
    "        return \"\"\n",
    "    s = str(raw_name).strip()\n",
    "\n",
    "    for pat in PROMO_PATTERNS:\n",
    "        s = re.sub(pat, \" \", s)\n",
    "\n",
    "    for pat in VOLUME_PATTERNS:\n",
    "        s = re.sub(pat, \" \", s)\n",
    "\n",
    "    s = s.replace(\"·\", \" \").replace(\"/\", \" \").replace(\"|\", \" \")\n",
    "    s = re.sub(r\"[_\\-–—]+\", \" \", s)\n",
    "    s = re.sub(r\"[^\\w가-힣\\s]\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def remove_leading_brand_if_match(canonical_name: str, brand: str) -> str:\n",
    "    if pd.isna(canonical_name):\n",
    "        return \"\"\n",
    "    s = str(canonical_name).strip()\n",
    "\n",
    "    if pd.isna(brand) or str(brand).strip() == \"\":\n",
    "        return s\n",
    "\n",
    "    b = str(brand).strip()\n",
    "    if not s:\n",
    "        return s\n",
    "\n",
    "    parts = s.split()\n",
    "    first = parts[0]\n",
    "\n",
    "    if first.lower() == b.lower():\n",
    "        s = \" \".join(parts[1:]).strip()\n",
    "        return re.sub(r\"\\s+\", \" \", s).strip()\n",
    "\n",
    "    if s.lower().startswith(b.lower() + \" \"):\n",
    "        s = s[len(b):].strip()\n",
    "        return re.sub(r\"\\s+\", \" \", s).strip()\n",
    "\n",
    "    return s\n",
    "\n",
    "def build_product_key(brand: str, canonical_name: str) -> str:\n",
    "    b = \"\" if pd.isna(brand) else str(brand).strip()\n",
    "    n = \"\" if pd.isna(canonical_name) else str(canonical_name).strip()\n",
    "    return re.sub(r\"\\s+\", \" \", f\"{b}__{n}\".strip(\"_\")).strip()\n",
    "\n",
    "def pick_col(df: pd.DataFrame, candidates: list[str], required_name: str):\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    raise KeyError(f\"필수 컬럼({required_name}) 없음. 후보={candidates} / 현재컬럼={list(df.columns)}\")\n",
    "\n",
    "# =========================\n",
    "# 2) CSV 적용 (원본 열 100% 유지 + 새 열만 추가)\n",
    "# =========================\n",
    "in_path = \"products_ingredients_final_essence.csv\"\n",
    "df = pd.read_csv(in_path)\n",
    "\n",
    "brand_col = pick_col(df, [\"brand\", \"브랜드\"], \"brand\")\n",
    "name_col  = pick_col(df, [\"product_name\", \"productName\", \"원래제품명\", \"제품명\"], \"product_name\")\n",
    "\n",
    "# ✅ 원본 열은 그대로 두고, 새 열만 추가\n",
    "df[\"canonical_name\"] = df[name_col].apply(normalize_product_name)\n",
    "df[\"canonical_name\"] = df.apply(lambda r: remove_leading_brand_if_match(r[\"canonical_name\"], r[brand_col]), axis=1)\n",
    "df[\"product_key\"] = df.apply(lambda r: build_product_key(r[brand_col], r[\"canonical_name\"]), axis=1)\n",
    "\n",
    "print(\"원본 컬럼 개수:\", len(df.columns))\n",
    "print(df[[name_col, \"canonical_name\", \"product_key\"]].head(20).to_string(index=False))\n",
    "\n",
    "out_path = \"products_ingredients_final_essence_brandremoved_keepcols.csv\"\n",
    "df.to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"\\n저장 완료: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb75bdac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'numpy' (<_frozen_importlib_external._NamespaceLoader object at 0x1113e0280>)>\n",
      "NO_VERSION\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np)\n",
    "print(getattr(np, \"__version__\", \"NO_VERSION\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cb94c0",
   "metadata": {},
   "source": [
    "### 중복되는 제품의 경우 첫번째 행만 남기고 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c091dd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# =========================\n",
    "# 0) 입력/출력 경로\n",
    "# =========================\n",
    "in_path = \"/mnt/data/table2_products_normalized_reordered.csv\"\n",
    "out_path = \"/mnt/data/table2_products_normalized_reordered_dedup.csv\"\n",
    "\n",
    "df = pd.read_csv(in_path)\n",
    "\n",
    "# =========================\n",
    "# 1) 중복 확인 (canonical_name 기준)\n",
    "# =========================\n",
    "key_col = \"canonical_name\"\n",
    "\n",
    "# 중복되는 행만 뽑기 (첫 행 포함)\n",
    "dup_mask = df.duplicated(key_col, keep=False)\n",
    "df_dups = df[dup_mask].copy()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"[중복 요약] 기준 컬럼: {key_col}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if df_dups.empty:\n",
    "    print(\"중복이 없습니다. (canonical_name 기준)\")\n",
    "else:\n",
    "    # 중복 그룹 크기 요약\n",
    "    dup_counts = (\n",
    "        df_dups.groupby(key_col)\n",
    "        .size()\n",
    "        .sort_values(ascending=False)\n",
    "    )\n",
    "\n",
    "    print(f\"중복 그룹 수: {dup_counts.shape[0]}\")\n",
    "    print(f\"중복 행 수(전체): {df_dups.shape[0]}\")\n",
    "    print(\"\\n중복 상위 20개 (canonical_name -> count):\")\n",
    "    print(dup_counts.head(20).to_string())\n",
    "\n",
    "    # 어떤 행이 중복인지 상세 출력 (상위 N개 그룹만)\n",
    "    TOP_N_GROUPS = 10\n",
    "    top_names = dup_counts.head(TOP_N_GROUPS).index.tolist()\n",
    "\n",
    "    # 출력 컬럼(있는 것만 출력)\n",
    "    show_cols_candidates = [\n",
    "        \"product_id\", \"category\", \"brand\",\n",
    "        \"canonical_name\", \"ingredients\", \"product_name\", \"product_key\"\n",
    "    ]\n",
    "    show_cols = [c for c in show_cols_candidates if c in df.columns]\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"[중복 상세] 상위 {TOP_N_GROUPS}개 canonical_name 그룹의 행들\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    df_dups_top = df_dups[df_dups[key_col].isin(top_names)].copy()\n",
    "    df_dups_top = df_dups_top.sort_values([key_col, \"product_id\"], kind=\"stable\")\n",
    "    print(df_dups_top[show_cols].to_string(index=False))\n",
    "\n",
    "# =========================\n",
    "# 2) 중복 제거 (첫 번째 행만 남김)\n",
    "# =========================\n",
    "df_dedup = df.drop_duplicates(subset=[key_col], keep=\"first\").copy()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"[Dedup 결과]\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"원본 행 수: {df.shape[0]}\")\n",
    "print(f\"Dedup 후 행 수: {df_dedup.shape[0]}\")\n",
    "print(f\"삭제된 행 수: {df.shape[0] - df_dedup.shape[0]}\")\n",
    "\n",
    "# =========================\n",
    "# 3) 저장\n",
    "# =========================\n",
    "df_dedup.to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"\\n저장 완료: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc7f988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "[삭제 대상 행 요약]\n",
      "================================================================================\n",
      "삭제될 행 수: 60\n",
      "\n",
      "[삭제된 product_id 목록]\n",
      "--------------------------------------------------------------------------------\n",
      "S15\n",
      "S29\n",
      "S31\n",
      "S32\n",
      "S39\n",
      "S49\n",
      "S50\n",
      "S63\n",
      "S97\n",
      "S98\n",
      "S99\n",
      "S104\n",
      "S109\n",
      "S121\n",
      "S125\n",
      "S135\n",
      "S141\n",
      "S153\n",
      "S163\n",
      "S167\n",
      "S170\n",
      "S172\n",
      "S173\n",
      "S175\n",
      "S176\n",
      "S177\n",
      "S188\n",
      "S189\n",
      "S196\n",
      "S204\n",
      "S218\n",
      "S226\n",
      "S230\n",
      "S236\n",
      "S248\n",
      "S252\n",
      "S258\n",
      "S263\n",
      "S265\n",
      "S267\n",
      "S269\n",
      "S271\n",
      "S273\n",
      "S279\n",
      "S288\n",
      "S294\n",
      "S295\n",
      "S296\n",
      "S301\n",
      "S302\n",
      "S306\n",
      "S311\n",
      "S314\n",
      "S316\n",
      "S319\n",
      "S322\n",
      "S324\n",
      "S327\n",
      "S328\n",
      "S329\n",
      "\n",
      "product_id 목록 저장 완료: /Users/eunjin/Downloads/deleted_product_ids.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# =========================\n",
    "# 0) 입력 경로\n",
    "# =========================\n",
    "in_path = \"/Users/eunjin/Downloads/table2_products_normalized_reordered.csv\"\n",
    "df = pd.read_csv(in_path)\n",
    "\n",
    "key_col = \"canonical_name\"\n",
    "id_col = \"product_id\"\n",
    "\n",
    "# =========================\n",
    "# 1) 삭제될 행들만 추출\n",
    "#    keep=\"first\" → 첫 행을 제외한 나머지가 삭제 대상\n",
    "# =========================\n",
    "deleted_mask = df.duplicated(subset=[key_col], keep=\"first\")\n",
    "df_deleted = df[deleted_mask].copy()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"[삭제 대상 행 요약]\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"삭제될 행 수: {df_deleted.shape[0]}\")\n",
    "\n",
    "# =========================\n",
    "# 2) 삭제된 product_id 출력\n",
    "# =========================\n",
    "deleted_ids = df_deleted[id_col].tolist()\n",
    "\n",
    "print(\"\\n[삭제된 product_id 목록]\")\n",
    "print(\"-\" * 80)\n",
    "for pid in deleted_ids:\n",
    "    print(pid)\n",
    "\n",
    "# =========================\n",
    "# 3) 필요하면 파일로 저장\n",
    "# =========================\n",
    "out_ids_path = \"/Users/eunjin/Downloads/deleted_product_ids.csv\"\n",
    "pd.DataFrame({id_col: deleted_ids}).to_csv(out_ids_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"\\nproduct_id 목록 저장 완료: {out_ids_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd9f40a",
   "metadata": {},
   "source": [
    "### 제거한 제품의 리뷰도 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84ebb4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "삭제 대상 product_id 개수: 60\n",
      "리뷰 원본 행 수: 16902\n",
      "================================================================================\n",
      "[리뷰 삭제 결과]\n",
      "================================================================================\n",
      "삭제된 리뷰 수: 3590\n",
      "남은 리뷰 수: 13312\n",
      "\n",
      "삭제된 리뷰가 있었던 product_id 상위 20개:\n",
      "product_id\n",
      "S104    100\n",
      "S32     100\n",
      "S248    100\n",
      "S319    100\n",
      "S316    100\n",
      "S314    100\n",
      "S329    100\n",
      "S311    100\n",
      "S177    100\n",
      "S39     100\n",
      "S109    100\n",
      "S230    100\n",
      "S163    100\n",
      "S29     100\n",
      "S15     100\n",
      "S294    100\n",
      "S50     100\n",
      "S295    100\n",
      "S296    100\n",
      "S271     93\n",
      "\n",
      "정리된 리뷰 파일 저장 완료: /Users/eunjin/Downloads/reviews_deduped.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# =========================\n",
    "# 0) 파일 경로\n",
    "# =========================\n",
    "# 삭제된 product_id 목록 (앞에서 만든 파일)\n",
    "deleted_ids_path = \"/Users/eunjin/Downloads/deleted_product_ids.csv\"\n",
    "\n",
    "# 리뷰 데이터\n",
    "reviews_path = \"/Users/eunjin/Downloads/table1_reviews.csv\"\n",
    "\n",
    "# 출력 파일\n",
    "out_reviews_path = \"/Users/eunjin/Downloads/reviews_deduped.csv\"\n",
    "\n",
    "# =========================\n",
    "# 1) 데이터 로드\n",
    "# =========================\n",
    "df_deleted_ids = pd.read_csv(deleted_ids_path)\n",
    "df_reviews = pd.read_csv(reviews_path)\n",
    "\n",
    "# 컬럼명\n",
    "id_col = \"product_id\"\n",
    "\n",
    "# 삭제 대상 product_id set\n",
    "deleted_id_set = set(df_deleted_ids[id_col].astype(str))\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"삭제 대상 product_id 개수:\", len(deleted_id_set))\n",
    "print(\"리뷰 원본 행 수:\", df_reviews.shape[0])\n",
    "\n",
    "# =========================\n",
    "# 2) 리뷰 삭제 (product_id 기준)\n",
    "# =========================\n",
    "mask_delete = df_reviews[id_col].astype(str).isin(deleted_id_set)\n",
    "df_reviews_deleted = df_reviews[mask_delete]\n",
    "df_reviews_kept = df_reviews[~mask_delete]\n",
    "\n",
    "# =========================\n",
    "# 3) 결과 출력\n",
    "# =========================\n",
    "print(\"=\" * 80)\n",
    "print(\"[리뷰 삭제 결과]\")\n",
    "print(\"=\" * 80)\n",
    "print(\"삭제된 리뷰 수:\", df_reviews_deleted.shape[0])\n",
    "print(\"남은 리뷰 수:\", df_reviews_kept.shape[0])\n",
    "\n",
    "# (선택) 어떤 product_id 리뷰가 지워졌는지 요약\n",
    "deleted_review_counts = (\n",
    "    df_reviews_deleted.groupby(id_col)\n",
    "    .size()\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "print(\"\\n삭제된 리뷰가 있었던 product_id 상위 20개:\")\n",
    "print(deleted_review_counts.head(20).to_string())\n",
    "\n",
    "# =========================\n",
    "# 4) 저장\n",
    "# =========================\n",
    "df_reviews_kept.to_csv(out_reviews_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"\\n정리된 리뷰 파일 저장 완료: {out_reviews_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03024415",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gnn)",
   "language": "python",
   "name": "gnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
